"""éæµå¼èŠå¤©å“åº”å¤„ç†æ¨¡å—ã€‚

æœ¬æ¨¡å—è´Ÿè´£å¤„ç†ä¸ä¸Šæ¸¸APIçš„éæµå¼äº¤äº’ï¼ŒåŒ…æ‹¬éæµå¼å“åº”è§£æå’Œç»“æœæ„å»ºã€‚
"""

import uuid
import re
import codecs
from datetime import datetime
from typing import Any

from curl_cffi.requests import AsyncSession

# å°è¯•ä½¿ç”¨ orjson åŠ é€Ÿ JSON æ“ä½œ
try:
    import orjson

    def json_loads(s: str) -> dict:
        """ä½¿ç”¨ orjson å¿«é€Ÿååºåˆ—åŒ–"""
        return orjson.loads(s)
except ImportError:
    import json

    json_loads = json.loads

from ...config import get_settings
from ...exceptions import UpstreamAPIError
from ...logger import get_logger
from ...models import (
    ChatRequest,
    ChatCompletionMessage,
    ChatCompletionChoice,
    ChatCompletionResponse,
    ChatCompletionUsage,
)
from ...utils.error_handler import handle_upstream_error

logger = get_logger(__name__)
settings = get_settings()

# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
QUERIES_PATTERN = re.compile(r'"queries":\s*\[(.*?)\]')
QUERY_ITEMS_PATTERN = re.compile(r'"([^"]+)"')
SUMMARY_SPLIT_PATTERN = re.compile(r"</summary>\n>")
DETAILS_SPLIT_PATTERN = re.compile(r"</details>\n")


async def process_non_streaming_response(
    chat_request: ChatRequest, access_token: str, prepare_request_data_func
) -> dict[str, Any]:
    """å¤„ç†éæµå¼å“åº”ã€‚

    :param chat_request: èŠå¤©è¯·æ±‚å¯¹è±¡
    :param access_token: è®¿é—®ä»¤ç‰Œ
    :param prepare_request_data_func: ç”¨äºå‡†å¤‡è¯·æ±‚æ•°æ®çš„å‡½æ•°
    :return: å®Œæ•´çš„èŠå¤©è¡¥å…¨å“åº”
    :raises UpstreamAPIError: å½“ä¸Šæ¸¸APIè¿”å›é”™è¯¯çŠ¶æ€ç æ—¶

    .. note::
       å“åº”æ ¼å¼éµå¾ªOpenAIçš„éæµå¼APIè§„èŒƒã€‚
    """
    async with AsyncSession(impersonate=settings.get_browser_version()) as session:  # type: ignore
        # ä»sessionè·å–curl_cffiè‡ªåŠ¨è®¾ç½®çš„User-Agent
        user_agent = session.headers.get("User-Agent", "")

        # å‡†å¤‡è¯·æ±‚æ•°æ®ï¼Œä¼ å…¥User-Agent
        zai_data, params, headers = await prepare_request_data_func(
            chat_request, access_token, streaming=False, user_agent=user_agent
        )

        full_response = ""
        reasoning_content = ""
        usage_info = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
        }

        request_id = params.get("requestId", "unknown")
        user_id = params.get("user_id", "unknown")
        timestamp = params.get("timestamp", "unknown")

        logger.info(
            "Non-streaming request initiated: request_id={}, user_id={}, model={}, upstream_url={}",
            request_id,
            user_id,
            chat_request.model,
            f"{settings.proxy_url}/api/chat/completions",
        )

        if settings.verbose_logging:
            logger.debug(
                "Non-streaming request details: request_id={}, upstream_url={}, headers={}, params={}, json_body={}",
                request_id,
                f"{settings.proxy_url}/api/chat/completions",
                {
                    k: v if k.lower() != "authorization" else v[:20] + "..."
                    for k, v in headers.items()
                },
                params,
                zai_data,
            )

        try:
            response = await session.post(
                f"{settings.proxy_url}/api/chat/completions",
                headers=headers,
                params=params,
                json=zai_data,
                timeout=300.0,
                stream=True,
            )
            try:
                if response.status_code != 200:
                    await handle_upstream_error(
                        response,
                        request_id,
                        user_id,
                        timestamp,
                        chat_request.model,
                        is_streaming=False,
                    )

                logger.info(
                    "Non-streaming response started: request_id={}, status_code={}, model={}",
                    request_id,
                    response.status_code,
                    chat_request.model,
                )

                chunk_count = 0

                async for line in response.aiter_lines():
                    if not line:
                        continue

                    # curl_cffiè¿”å›bytesï¼Œéœ€è¦è§£ç 
                    if isinstance(line, bytes):
                        line = line.decode("utf-8")

                    if not line.startswith("data:"):
                        continue

                    json_str = line[6:]

                    # è¾“å‡ºåŸå§‹SSEæ•°æ®å—
                    if settings.verbose_logging:
                        logger.debug(
                            "Non-streaming SSE line: request_id={}, data={}",
                            request_id,
                            json_str[:300],
                        )

                    if not json_str or json_str in ("[DONE]", "DONE", "done"):
                        if json_str in ("[DONE]", "DONE", "done"):
                            logger.info(
                                "Non-streaming [DONE] received: request_id={}",
                                request_id,
                            )
                        break

                    try:
                        json_object = json_loads(json_str)
                    except Exception:
                        logger.warning(
                            "Invalid JSON in non-stream: line={}", line[:100]
                        )
                        continue

                    if json_object.get("type") != "chat:completion":
                        continue

                    data = json_object.get("data", {})
                    phase = data.get("phase")
                    delta_content = data.get("delta_content", "")
                    edit_content = data.get("edit_content", "")

                    # è®°å½•ç”¨é‡
                    if data.get("usage"):
                        usage_info = data["usage"]
                        if settings.verbose_logging:
                            logger.debug(
                                "Non-streaming usage received: request_id={}, usage={}",
                                request_id,
                                usage_info,
                            )

                    # å¤„ç†tool_callé˜¶æ®µï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
                    if phase == "tool_call":
                        if (
                            edit_content
                            and "<glm_block" in edit_content
                            and "search" in edit_content
                        ):
                            try:
                                decoded = edit_content
                                try:
                                    decoded = (
                                        edit_content.encode("utf-8")
                                        .decode("unicode_escape")
                                        .encode("latin1")
                                        .decode("utf-8")
                                    )
                                except:
                                    try:
                                        decoded = codecs.decode(
                                            edit_content, "unicode_escape"
                                        )
                                    except:
                                        pass

                                queries_match = QUERIES_PATTERN.search(decoded)
                                if queries_match:
                                    queries_str = queries_match.group(1)
                                    queries = QUERY_ITEMS_PATTERN.findall(queries_str)
                                    if queries:
                                        search_info = "ğŸ” **æœç´¢ï¼š** " + "ã€€".join(
                                            queries[:5]
                                        )
                                        reasoning_content += f"\n\n{search_info}\n\n"
                            except Exception:
                                pass
                        continue

                    # æ€è€ƒé˜¶æ®µï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
                    elif phase == "thinking":
                        if delta_content:
                            if delta_content.startswith("<details"):
                                cleaned = (
                                    SUMMARY_SPLIT_PATTERN.split(delta_content)[
                                        -1
                                    ].strip()
                                    if "</summary>\n>" in delta_content
                                    else delta_content
                                )
                            else:
                                cleaned = delta_content
                            reasoning_content += cleaned
                            chunk_count += 1
                            if settings.verbose_logging:
                                logger.debug(
                                    "Non-streaming thinking chunk: request_id={}, content={}",
                                    request_id,
                                    cleaned[:200],
                                )

                    # ç­”æ¡ˆé˜¶æ®µï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
                    elif phase == "answer":
                        if edit_content and "</details>\n" in edit_content:
                            content_after = DETAILS_SPLIT_PATTERN.split(edit_content)[
                                -1
                            ]
                            if content_after:
                                full_response += content_after
                                if settings.verbose_logging:
                                    logger.debug(
                                        "Non-streaming answer chunk (from edit): request_id={}, length={}",
                                        request_id,
                                        len(content_after),
                                    )
                        elif delta_content:
                            full_response += delta_content
                            if settings.verbose_logging:
                                logger.debug(
                                    "Non-streaming answer chunk: request_id={}, length={}",
                                    request_id,
                                    len(delta_content),
                                )
                        chunk_count += 1

                    # otheré˜¶æ®µ
                    elif phase == "other":
                        if delta_content:
                            full_response += delta_content
                            if settings.verbose_logging:
                                logger.debug(
                                    "Non-streaming other chunk: request_id={}, content={}",
                                    request_id,
                                    delta_content[:200],
                                )
                        chunk_count += 1
                        # æ£€æŸ¥æ˜¯å¦æœ‰doneæ ‡è®°ï¼Œå¦‚æœæœ‰åˆ™ç»“æŸ
                        if data.get("done"):
                            logger.info(
                                "Non-streaming done in other phase: request_id={}",
                                request_id,
                            )
                            break

                    # doneé˜¶æ®µ
                    elif phase == "done":
                        logger.info(
                            "Non-streaming done signal: request_id={}", request_id
                        )
                        break

            finally:
                await response.aclose()
        except UpstreamAPIError:
            raise
        except Exception as e:
            if "status" in str(type(e).__name__).lower() or "HTTP" in str(e):
                status_code = getattr(e, "status_code", 500)
                logger.error(
                    "Unexpected HTTP status error (non-streaming): status_code={}, error={}, request_id={}, user_id={}, timestamp={}",
                    status_code,
                    str(e),
                    request_id,
                    user_id,
                    timestamp,
                )
                raise UpstreamAPIError(
                    status_code,
                    f"HTTPé”™è¯¯ {status_code}",
                    "http_error",
                ) from e
            elif "request" in str(type(e).__name__).lower():
                logger.error(
                    "Upstream request error (non-streaming): error_type={}, error={}, request_id={}, user_id={}, timestamp={}",
                    type(e).__name__,
                    str(e),
                    request_id,
                    user_id,
                    timestamp,
                )
                raise UpstreamAPIError(
                    500, f"è¯·æ±‚é”™è¯¯: {str(e)}", "request_error"
                ) from e
            else:
                logger.error(
                    "Unexpected error (non-streaming): error_type={}, error={}, request_id={}, user_id={}, timestamp={}",
                    type(e).__name__,
                    str(e),
                    request_id,
                    user_id,
                    timestamp,
                )
                raise UpstreamAPIError(
                    500, f"æœªçŸ¥é”™è¯¯: {str(e)}", "unknown_error"
                ) from e

    # æ¸…ç†å¹¶è¿”å›
    full_response = (full_response or "").strip()
    reasoning_content = (reasoning_content or "").strip()

    # è‹¥æ²¡æœ‰èšåˆåˆ°ç­”æ¡ˆï¼Œä½†æœ‰æ€è€ƒå†…å®¹ï¼Œåˆ™ä¿åº•è¿”å›æ€è€ƒå†…å®¹
    if not full_response and reasoning_content:
        full_response = reasoning_content

    logger.info(
        "Non-streaming completion: request_id={}, model={}, chunks={}, response_length={}, usage={}",
        request_id,
        chat_request.model,
        chunk_count,
        len(full_response),
        usage_info,
    )

    # ä½¿ç”¨ Pydantic æ¨¡å‹æ„å»ºå“åº”
    message = ChatCompletionMessage(role="assistant", content=full_response)
    choice = ChatCompletionChoice(index=0, message=message, finish_reason="stop")

    response = ChatCompletionResponse(
        id=f"chatcmpl-{uuid.uuid4()}",
        created=int(datetime.now().timestamp()),
        model=chat_request.model,
        choices=[choice],
        usage=ChatCompletionUsage(**usage_info) if usage_info else None,
    )
    
    return response.model_dump(exclude_none=True)